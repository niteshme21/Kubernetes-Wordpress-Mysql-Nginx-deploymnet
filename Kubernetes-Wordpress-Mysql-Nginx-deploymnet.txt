Kubernetes on AWS using Kop

1. Launch Ubuntu 18.04 Linux EC2 t2 micro free teir instance in AWS (Kubernetes Client)



2. Create and attach IAM role to EC2 Instance.
Kops need permissions to access
	S3 full access
	EC2 full access
	VPC full access
	Route53 full access
	Autoscaling full access
        Loadbalancing Full access
        AdministratorAccess


3. Install Kops on EC2


Command#$ curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64


Command#$ chmod +x kops-linux-amd64
Command#$ sudo mv kops-linux-amd64 /usr/local/bin/kops  




4. Install kubectl

Command#$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl

Command#$ chmod +x ./kubectl

Command#$ sudo mv ./kubectl /usr/local/bin/kubectl

IMP Commands 

Command#$ sudo apt-get update -y
Command#$ sudo apt-get install awscli -y	

 

5. Create S3 bucket in AWS
S3 bucket is used by kubernetes to persist cluster state, lets create s3 bucket using aws cli Note: Make sure you choose bucket name that is uniqe accross all aws accounts

Command#$ aws s3 mb s3://nitesh123.in --region ap-south-1


6. Create private hosted zone in AWS Route53
1.	Head over to aws Route53 and create hostedzone
2.	Choose name for example (nitesh123.in)
3.	Choose type as privated hosted zone for VPC
4.	Select default vpc in the region you are setting up your cluster    example ((mumbai- ap-south-1a private Vpc)) 
5.	Hit create






7 Configure environment variables.
Open .bashrc file  Important Command below 

	
Command#$  vi ~/.bashrc



put the entry after Fi*************** 

if [ -z "$debian_chroot" ] && [ -r /etc/debian_chroot ]; then
    debian_chroot=$(cat /etc/debian_chroot)
fi

Need to enter the below text here and replace nitesh123,in accoding to your choice

export KOPS_CLUSTER_NAME=nitesh123.in
export KOPS_STATE_STORE=s3://nitesh123.in

###  :x or :wq! will save the file  ### 


Then running command to reflect variables added to .bashrc


Command#$  source ~/.bashrc




8. Create ssh key pair


This keypair is used for ssh into kubernetes cluster


Command#$   ssh-keygen

hit enter enter enter 





9. Create a Kubernetes cluster definition. Paste below command hit Enter


Copy whole command given below and paste and hit enter

Command#$  

kops create cluster \
--state=${KOPS_STATE_STORE} \
--node-count=2 \
--master-size=t2.micro \
--node-size=t2.micro \
--zones=ap-south-1a,ap-south-1b \
--name=${KOPS_CLUSTER_NAME} \
--dns private \
--master-count 1


10. Create kubernetes cluster



Command#$  kops update cluster --yes



Wait 10 minute and enter below command to validate your cluster is running or not

kops validate cluster  

Above command may take some time to create the required infrastructure resources on AWS. Execute the validate command to check its status and wait until the cluster becomes ready
kops validate cluster
For the above above command, you might see validation failed error initially when you create cluster and it is expected behaviour, you have to wait for some more time and check again.





11. To connect to the master



Command#$  ssh ubuntu@ec2-52-66-74-217.ap-south-1.compute.amazonaws.com  master IP or Node IP to connect master or  NOde 


(((ubuntu@ec2-52-66-74-217.ap-south-1.compute.amazonaws.com)))) this you can get in AWS by hiting connect to your instance you will see this context 




(((TO Destroy the kubernetes cluster))))


Command#$  kops delete cluster  --yes







